{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29038450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randrange\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e751894",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X = diabetes['data']\n",
    "y = diabetes['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMO_algorithm:\n",
    "    def __init__(self, X, y, C, tol, kernel, use_linear_optim):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.kernel = kernel\n",
    "        self.use_linear_optim = use_linear_optim\n",
    "        \n",
    "        self.n_train, self.n_feature = np.shape(self.X)\n",
    "        self.alphas = np.zeros( self.n_train)\n",
    "        \n",
    "        self.errors = np.zeros(self.n_train)\n",
    "        self.epsilon = 0.001\n",
    "        \n",
    "        self.weight = np.zeros(self.n_feature)\n",
    "        self.b = 0\n",
    "    # have to maximize:\n",
    "        # L(w, b, a) = 1/2||w||^2 - sum( ai*( yi * f(w,b) - 1) )\n",
    "        # f(w, b) = w^T.xj - b\n",
    "        # dL/dw => w = sum( ai*yi*xi)\n",
    "        # dL/db => sum( ai*yi) = 0\n",
    "        # Dual form give that w = sum( ai*yi*x[i] ) \n",
    "        # so L(w, b ,a) = sum( ai) - 1/2.sum(  yi*yj*ai*aj*<xi,xj> )\n",
    "        # SMO take at, as and minize quadratic function\n",
    "    def output(self, i): # i is index of X_train array( calculate f(w,x) )\n",
    "        if self.use_linear_opt:\n",
    "            return float(np.dot( self.weight.T, self.X[i])) - self.b\n",
    "        else:\n",
    "            return np.sum( [\n",
    "                self.alphas[j] * self.y[j] * self.y[i] * self.kernel( self.X[j], self,X[i])\n",
    "                for j in range(self.n_train)\n",
    "            ]) - self.b\n",
    "            \n",
    "    # add regularization:\n",
    "    # have to minimize 1/2 * ||w||^2 + C.sum( ksi[i])\n",
    "                    # have yi*f(w,b) >= 1 - ksi[i]\n",
    "                    # and have ksi[i] >=0\n",
    "    # Lagrange dual form: L(w, b, ksi, a, r) =\n",
    "        # 1/2* ||w||^2 + C.sum(ksi[i]) - sum( ai*yi*f(w,b) - 1 + ksi[i]) - sum(ri*ksi[i])\n",
    "            # ai and ri are Langrange multipliers and >=0\n",
    "        # take derivatives:\n",
    "            # have to maximize sum(ai) - 1/2*sum( yi*yj*ai*aj*<xi,xj>)\n",
    "                    #have 0<= ai <= C\n",
    "                    # and sum(ai*yi) = 0\n",
    "                    # and w = sum( ai*yi*x[i] ) \n",
    "    def get_error(self, i1):\n",
    "        if 0 < self.alphas[i1] < self.C:\n",
    "            return self.errors[i1]\n",
    "        else:\n",
    "            return self.output(i1) - self.y[i1]\n",
    "        \n",
    "    def error(self, i2):\n",
    "        return self.output(i2) - self.y[i2]\n",
    "    \n",
    "    def get_non_bound_indexes(self):\n",
    "        return np.where(np.logical_and( self.alphas > 0, self.alphas < self.C))[0]\n",
    "    \n",
    "    # loop over examples where alpha is not 0 and C\n",
    "    # they are the most likely to violate the KKT conditions\n",
    "    # according to SMO, we have 0< <= ai <= C and have to chose ai to maximize quadratic funcion\n",
    "    # ai = 0 => yi*f(w,b) >=1\n",
    "    # ai = C => yi*f(w,b) <=1\n",
    "    # 0 < ai < C => yi*f(w,b) = 1 # KKT conditions\n",
    "    def first_heuristic(self):\n",
    "        num_changed = 0 # number of examples for which Lagrange Multipliers have been updated\n",
    "        non_bound_idx = self.get_non_bound_indexes()\n",
    "        \n",
    "        for i in non_bound_idx:\n",
    "            num_change += self.examine_example(i)\n",
    "        return num_changed\n",
    "    \n",
    "    def examine_example(self, i2):\n",
    "        self.y2 = self.y[i2]\n",
    "        self.a2 = self.alphas[i2]\n",
    "        self.X2 = self.X[i2]\n",
    "        self.E2 = self.get_error(i2)\n",
    "        \n",
    "        r2 = self.E2 * self.y2\n",
    "        \n",
    "        if not (( r2 < - self.tol and self.a2 < self.C) or \n",
    "               (r2 > self.tol and self.a2 > 0)):\n",
    "            # The KKT conditions are met, SMO looks at another example.\n",
    "            return 0\n",
    "        non_bound_idx = list(self.get_non_bound_indexes())\n",
    "        i1 = self.second_heuristic(non_bound_idx)\n",
    "        \n",
    "        # Second heuristic A: choose the Lagrange multiplier which\n",
    "        # maximizes the absolute error.\n",
    "        if i1 >=0 and self.take_step(i1,i2):\n",
    "            return 1\n",
    "        \n",
    "        # Second heuristic B: Look for examples making positive\n",
    "        # progress by looping over all non-zero and non-C alpha,\n",
    "        # starting at a random point.\n",
    "        if len(non_bound_idx) > 0:\n",
    "            rand_i = randrange(len(non_bound_idx))\n",
    "            for i1 in non_bound_idx[rand_i:] + non_bound_idx[: rand_i]:\n",
    "                if self.take_step(i1,i2):\n",
    "                    return 1\n",
    "        #Second heuristic C: Look for examples making positive progress\n",
    "        # by looping over all possible examples, starting at a random\n",
    "        # point.\n",
    "        rand_i = randrange(self.m)\n",
    "        all_indices = list(range(self.m))\n",
    "        for i1 in all_indices[rand_i:] + all_indices[:rand_i]:\n",
    "            if self.take_step(i1, i2):\n",
    "                return 1\n",
    "\n",
    "        # Extremely degenerate circumstances, SMO skips the first example.\n",
    "        return 0\n",
    "    \n",
    "    def second_heuristic(self, non_bound_indices):\n",
    "        i1 = -1\n",
    "        if len(non_bound_indices) >1:\n",
    "            max = 0\n",
    "            for j in non_bound_indices:\n",
    "                E1 = self.errors[j] - self.y[j]\n",
    "                step = abs(E1 - self.E2)\n",
    "                if step > max:\n",
    "                    max = step\n",
    "                    i1 = j\n",
    "        return i1\n",
    "    \n",
    "    def take_step(self, i1, i2):\n",
    "        if i1 == i2:\n",
    "            return 0\n",
    "        \n",
    "        a1 = self.alphas[i1]\n",
    "        y1 = self.y[i1]\n",
    "        X1 = self.X[i1]\n",
    "        E1 = self.get_error(i1)\n",
    "        s = y1 * self.y2\n",
    "        \n",
    "        # bound of the new alpha2\n",
    "        # because we have 0 <= ai <=C, and a1*y1 + a2*y2 =k=- sum(ai*yi for i >2) is fixed\n",
    "        # so we have 0<= a1 <= C, H<= a2 <= L\n",
    "        if y1 != self.y2:\n",
    "            L = max(0, self.a2 - a1)\n",
    "            H = min(self.C, self.a2 + a1)\n",
    "        else:\n",
    "            L = max(0, self.a2+ a1 - self.C)\n",
    "            H = min(self.C, self.a2 + a1)\n",
    "        \n",
    "        if L == H:\n",
    "            return 0 # because now a2 is fixed, so we can not change a1, a2\n",
    "        \n",
    "        k11 = self.kernel(X1, X1)\n",
    "        k12 = self.kernel(X1, self.X[i2])\n",
    "        k22 = self.kernel(self.X[i2], self.X[i2])\n",
    "        \n",
    "        # we have to calculate a2 base on maximizing quadratic function\n",
    "        # W(a1,a2,...) = sum(ai) - 1/2*sum(ai*aj*yi*yj*kernel(xi,xj))\n",
    "        # but a1 = y1*( k - a2*y2)\n",
    "        # so we have W(y1*(k-a2*y2),a2,...) = .... => quadratic function\n",
    "        # we maximize W by derivaticve and check bound of a2(L and H)\n",
    "        # dW/da2 = -y1*y2 + 1 - 1/2( 2*a2*y2*y2*k(x2, x2) \n",
    "        #                           - 2*( k - a2*y2)*y2*ker(x1,x1)\n",
    "        #                           - 2*(2*a2*y2 + k)*y2*ker(x1,x2) ) # we have ker(x1,x2) and ker(x2,x1) so have to multiply by 2 \n",
    "        # and so we have -1*eta*a2 = ...\n",
    "        \n",
    "        eta = k11 + k22 - 2k12\n",
    "        # only when eta is possitive because it satisfy Mercer's condition\n",
    "        if eta >0:\n",
    "            a2_new = self.a2 + self.y2*(E1 - self.E2) / eta\n",
    "            if a2_new <L:\n",
    "                a2_new = L\n",
    "            elif a2_new >H:\n",
    "                a2_new = H\n",
    "        else:\n",
    "            # Under unusual cicumstances, eta will not be positive.\n",
    "            # Equation 19\n",
    "            f1 = y1 * (E1 + self.b) - a1 * k11 - s * self.a2 * k12\n",
    "            f2 = self.y2 * (self.E2 + self.b) - s * a1 * k12 \\\n",
    "                 - self.a2 * k22\n",
    "            L1 = a1 + s(self.a2 - L)\n",
    "            H1 = a1 + s * (self.a2 - H)\n",
    "            Lobj = L1 * f1 + L * f2 + 0.5 * (L1 ** 2) * k11 \\\n",
    "                   + 0.5 * (L ** 2) * k22 + s * L * L1 * k12\n",
    "            Hobj = H1 * f1 + H * f2 + 0.5 * (H1 ** 2) * k11 \\\n",
    "                   + 0.5 * (H ** 2) * k22 + s * H * H1 * k12\n",
    "\n",
    "            if Lobj < Hobj - self.eps:\n",
    "                a2_new = L\n",
    "            elif Lobj > Hobj + self.eps:\n",
    "                a2_new = H\n",
    "            else:\n",
    "                a2_new = self.a2\n",
    "                \n",
    "        # If alpha2 did not change enough the algorithm\n",
    "        # returns without updating the multipliers.\n",
    "        if abs(a2_new - self.a2) < self.eps * (a2_new + self.a2 \\\n",
    "                                                       + self.eps):\n",
    "            return 0\n",
    "        \n",
    "        # if succesfully caculate a2, we then calculate a1\n",
    "        a1_new = a1 + s*( self.a2 - a2_new)\n",
    "        new_b = self.compute_b(E1, a1,a1_new, a2_new, k11,k12,k22,y1)\n",
    "        delta_b = new_b - self.b\n",
    "        self.b = new_b\n",
    "        \n",
    "        if self.use_linear_optim:\n",
    "            self.w = self.w + y1*(a1_new- a1)*X1 + self.y2 * (a2_new - self.a2)*self.X2\n",
    "    # Update the error cache using the new Lagrange multipliers.\n",
    "        delta1 = y1 * (a1_new - a1)\n",
    "        delta2 = self.y2 * (a2_new - self.a2)\n",
    "\n",
    "        # Update the error cache.\n",
    "        for i in range(self.m):\n",
    "            if 0 < self.alphas[i] < self.C:\n",
    "                self.errors[i] += delta1 * self.kernel(X1, self.X[i]) + \\\n",
    "                                  delta2 * self.kernel(self.X2, self.X[i]) \\\n",
    "                                  - delta_b\n",
    "\n",
    "        self.errors[i1] = 0\n",
    "        self.errors[i2] = 0\n",
    "\n",
    "        self.alphas[i1] = a1_new\n",
    "        self.alphas[i2] = a2_new\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def compute_b(self, E1, a1, a1_new, a2_new, k11, k12, k22, y1):\n",
    "        # Equation 20\n",
    "        b1 = E1 + y1 * (a1_new - a1) * k11 + \\\n",
    "             self.y2 * (a2_new - self.a2) * k12 + self.b\n",
    "\n",
    "        # Equation 21\n",
    "        b2 = self.E2 + y1 * (a1_new - a1) * k12 + \\\n",
    "             self.y2 * (a2_new - self.a2) * k22 + self.b\n",
    "\n",
    "        if (0 < a1_new) and (self.C > a1_new):\n",
    "            new_b = b1\n",
    "        elif (0 < a2_new) and (self.C > a2_new):\n",
    "            new_b = b2\n",
    "        else:\n",
    "            new_b = (b1 + b2) / 2.0\n",
    "        return new_b\n",
    "    \n",
    "    def main_routine(self):\n",
    "        num_changed = 0\n",
    "        examine_all = True\n",
    "\n",
    "        while num_changed > 0 or examine_all:\n",
    "            num_changed = 0\n",
    "\n",
    "            if examine_all:\n",
    "                for i in range(self.m):\n",
    "                    num_changed += self.examine_example(i)\n",
    "            else:\n",
    "                num_changed += self.first_heuristic()\n",
    "\n",
    "            if examine_all:\n",
    "                examine_all = False\n",
    "            elif num_changed == 0:\n",
    "                examine_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1826e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecea101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651fccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
